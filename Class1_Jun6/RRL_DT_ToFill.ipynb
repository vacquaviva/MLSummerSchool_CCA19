{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a notebook to run a simple binary classification algorithm, using Decision Trees.\n",
    "\n",
    "#Author: Viviana Acquaviva\n",
    "#License: BSD but really should be TBD - just be nice.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#Notes: \n",
    "\n",
    "#Data come from here\n",
    "#from astroML.datasets import fetch_rrlyrae_combined\n",
    "#X, y = fetch_rrlyrae_combined()\n",
    "\n",
    "#As I was browsing around, I found some useful examples here:\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "#https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's read in the data in a data frame, and take a look at them\n",
    "\n",
    "Train = pd.read_csv('RRLTrainSet.csv', index_col = 0)\n",
    "Test = pd.read_csv('RRLTestSet.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This builds the four arrays (features/labels x train/test) needed by all sklearn ML models\n",
    "\n",
    "X_train = Train.drop(['label'], axis=1)\n",
    "y_train = Train['label']\n",
    "\n",
    "X_test = Test.drop(['label'], axis=1)\n",
    "y_test = Test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model alert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we build a model in sklearn. For reproducibility purposes, we will fix the random seed in the Decision Tree. But what is randomized in Decision Trees?\n",
    "\n",
    "\n",
    "From the docs: The features are always randomly permuted at each split. \n",
    "Therefore, the best found split may vary, even with the same training data \n",
    "and max_features=n_features, if the improvement of the criterion is identical \n",
    "for several splits enumerated during the search of the best split. \n",
    "To obtain a deterministic behaviour during fitting, random_state has to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might recognize a few familiar attributes up there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how we fit a model! Fitting a model means that we build the architecture to make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the model has built a set of questions (splits) that would inform the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bit below is to visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            model,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = list(X_train.columns),\n",
    "            class_names = ['Not var','Var'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "\n",
    "What is the accuracy score (% of correct classifications) on the training set, based on the tree?\n",
    "    \n",
    "How can we visualize it?\n",
    "\n",
    "How can we figure out the accuracy on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell below shows us the splits made by the decision tree above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill splits\n",
    "\n",
    "#Plots training data\n",
    "plt.scatter(X_train['u-g'], X_train['r-i'], \\\n",
    "            c = y_train.iloc[:,0].values, marker = '*', s =20, label = None, cmap = 'brg')\n",
    "plt.axvline(x=   , linewidth =1, label = '1st split')\n",
    "plt.axvline(x=   , linewidth =1, ls = '--', label = '2nd split')\n",
    "plt.axhline(y=   , linewidth =1, ls = '-.', xmin = 0.32, xmax=0.48, label = '3rd split')\n",
    "\n",
    "#Plots test data\n",
    "plt.scatter(X_test['u-g'], X_test['r-i'], \\\n",
    "            c = y_test.iloc[:,0].values, marker = 'o', s =20, label = None, cmap = 'brg')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now time to get real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbig = pd.read_csv('RRLyrae_features.txt', names = ['u-g', 'g-r', 'r-i', 'i-z'])\n",
    "ybig = pd.read_csv('RRLyrae_labels.txt', header = None).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot ALL the data, ahem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xbig['u-g'], Xbig['r-i'], \\\n",
    "            c = ybig.iloc[:,0].values, marker = '*', s =20, label = None, cmap = 'brg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some data thinking.\n",
    "\n",
    "<br>\n",
    "What can we say about this data set?\n",
    "\n",
    "Do you expect a decision tree to be an optimal classifier, based on the shape of the data?\n",
    "\n",
    "How would a classifier that puts everything in the \"non-RR Lyrae\" box fare on this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answers go here :) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how our previous algorithm would fare on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xbig['u-g'], Xbig['r-i'], \\\n",
    "            c = ybig.iloc[:,0].values, marker = '*', s =20, label = None, cmap = 'brg')\n",
    "plt.axvline(x=0.218, linewidth =1, label = '1st split')\n",
    "plt.axvline(x=0.147, linewidth =1, ls = '--', label = '2nd split')\n",
    "plt.axhline(y=0.035, linewidth =1, ls = '-.', xmin = 0.53, xmax=0.65, label = '3rd split')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How is our old tree doing? What is it getting right and wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answers go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do our training process again! Here we don't have separate train and test splits so we can create them, we'll call them X_trainb, X_testb etc (for \"big\"). Note: we are not doing cross validation yet, which is bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same plotting routine as above to visualize the new tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            modelbig, #note name change\n",
    "            out_file =  dot_data,\n",
    "            feature_names = list(X_trainb.columns), #here too\n",
    "            class_names = ['Not var','Var'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at those colors and then evaluate how the tree is doing on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is high, as expected! But is it meaningful? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an unbalanced data set, other metrics are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define recall, estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define precision, estimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: what have we seen so far?\n",
    "\n",
    "Let's talk about what we should be doing to optimize this classifier, going back to the tools we mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideas here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can customize this cell as we try new models\n",
    "\n",
    "modelX = DecisionTreeClassifier(......)\n",
    "modelX.fit(X_trainb,y_trainb)\n",
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            modelX,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = list(X_trainb.columns),\n",
    "            class_names = ['Not var','Var'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And then look at some of these\n",
    "\n",
    "print(metrics.accuracy_score(y_trainb, modelX.predict(X_trainb)))\n",
    "print(metrics.precision_score(y_trainb, modelX.predict(X_trainb)))\n",
    "print(metrics.recall_score(y_trainb, modelX.predict(X_trainb)))\n",
    "\n",
    "print(metrics.accuracy_score(y_testb, modelXpredict(X_testb)))\n",
    "print(metrics.precision_score(y_testb, modelX.predict(X_testb)))\n",
    "print(metrics.recall_score(y_testb, modelX.predict(X_testb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
